# -*- coding: utf-8 -*-
"""DCGAN PyTorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hi5Twaw6WzwvGmV73T4D69sdxn4Kzu9U

# Libraries
"""

import os
import sys
import time

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import datasets
import torchvision.utils as vutils

import numpy as np
from tqdm import tqdm
from numpy.random import rand
from numpy.random import randn
import matplotlib.pyplot as plt



"""# Config"""

class Configs:
  lr = 0.0002
  beta_1 = 0.5
  epochs = 50
  batch_size = 128
  noise_dim = 100
  num_observation = 16 # Number of observation noises

  img_size = (64, 64)
  num_channel = 3

  ngf = 64             # Number of generator's filter
  ndf = 64             # Number of discriminator's filter
  num_workers = 0      # Something relate to the number of cores of CPU. Set it to be 0 when using Colab.
  GPU = True

opt = Configs()

#%%

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

#%% """# Data Loading"""

transforms = torchvision.transforms.Compose([
  torchvision.transforms.Resize(opt.img_size),
  torchvision.transforms.ToTensor(),
  torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # Good value by rule of thumbs
])

image_ds = datasets.ImageFolder(root = r'G:\My Drive\Colab Notebooks\PyTorch DCGAN\Anime-Face-Dataset',
                                transform = transforms)
imageLoader = torch.utils.data.DataLoader(image_ds, batch_size = opt.batch_size,
                         shuffle = True, num_workers = opt.num_workers)

num_images = len(image_ds)
num_batch = len(image_ds) // opt.batch_size
print('Dataset contains {} images.'.format(num_images))
print('Dataset contains {} batches.'.format(len(image_ds) // opt.batch_size))

# for i, data in enumerate(imageLoader, 0):
#     print(data[i][0])
#     img = data[i][0]
#     img = img / 2 + 0.5     # unnormalize
#     npimg = img.numpy()
#     plt.imshow(np.transpose(npimg, (1, 2, 0)))
#     plt.show()

#%% 
"""# Define Models

## Generator
"""

generator = nn.Sequential(
    nn.ConvTranspose2d(opt.noise_dim, opt.ngf * 8, kernel_size = 4, stride = 1, padding = 0, bias = False), # 4x4x512
    nn.BatchNorm2d(opt.ngf * 8),
    nn.ReLU(inplace = True),

    nn.ConvTranspose2d(opt.ngf * 8, opt.ngf * 4, 4, 2, 1, bias = False), # 8x8x256
    nn.BatchNorm2d(opt.ngf * 4),
    nn.ReLU(inplace = True),

    nn.ConvTranspose2d(opt.ngf * 4, opt.ngf * 2, 4, 2, 1, bias = False), # 16x162x128
    nn.BatchNorm2d(opt.ngf * 2),
    nn.ReLU(inplace = True),

    nn.ConvTranspose2d(opt.ngf * 2, opt.ngf, 4, 2, 1, bias = False), # 32x32x64
    nn.BatchNorm2d(opt.ngf),
    nn.ReLU(inplace = True),
  
    nn.ConvTranspose2d(opt.ngf, opt.num_channel, 4, 2, 1, bias = False), # 64x64x3
    nn.Tanh()
)

#%% 
"""### Test generator
Generate latent point and feed it into the untrained generator. 
"""

fixed_noise = torch.randn(opt.num_observation, opt.noise_dim,1,1)

plt.figure(figsize=(12, 12))
for i in range(opt.num_observation):
  plt.subplot(4, 4, i+1)
  fixed_img = generator(fixed_noise)[i]
  fixed_img = (fixed_img/2+0.5).to('cpu')
  fixed_img = fixed_img.permute(1, 2, 0).detach()
  plt.imshow(fixed_img.numpy())
  plt.axis('off')
plt.suptitle('Generated images with untrained generator', fontsize = 24)
plt.show()

#%% """## Discriminator"""

discriminator = nn.Sequential(
    nn.Conv2d(opt.num_channel, opt.ndf, 4, 2, 1, bias = False),   # 32x32x64
    nn.LeakyReLU(inplace = True),

    nn.Conv2d(opt.ndf, opt.ndf * 2, 4, 2, 1, bias = False),       # 16x16x128
    nn.BatchNorm2d(opt.ndf * 2),
    nn.LeakyReLU(inplace = True),

    nn.Conv2d(opt.ndf * 2, opt.ndf * 4, 4, 2, 1, bias = False),   # 8x8x256
    nn.BatchNorm2d(opt.ndf * 4),
    nn.LeakyReLU(inplace = True),
    
    nn.Conv2d(opt.ndf * 4, opt.ndf * 8, 4, 2, 1, bias = False),   # 4x4x512
    nn.BatchNorm2d(opt.ndf * 8),
    nn.LeakyReLU(inplace = True),

    nn.Conv2d(opt.ndf * 8, 1, 4, 2, 0, bias = False),             # Flatten
    nn.Sigmoid()
)

#%% """## Optimizers and Loss Function"""

optimG = optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.beta_1, 0.999))
optimD = optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.beta_1, 0.999))

criterion = nn.BCELoss()

observe_noise = torch.randn(16, opt.noise_dim, 1, 1)

if opt.GPU:
  generator.cuda()
  discriminator.cuda()
  criterion.cuda()

#%% """# Training"""

loss_d_list = []
loss_g_list = []


print('Begin Training for {} epochs.'.format(opt.epochs))

for i in range(opt.epochs):
  print("Start epoch {}/{} ".format(i, opt.epochs))
  for ix, data in enumerate(imageLoader, 0):                # data is a list of [inputs, labels]
    real_img, _ = data                                      # real_img is a list with each element represents 1 image. len = 256. (256, 3, 64, 64)
    inputs = real_img
    noise = torch.randn(len(real_img), opt.noise_dim, 1, 1) # create 256 noises with given dimensions. (256, 100, 1, 1)
    labels = torch.ones(len(real_img))                      # labels for positive

    if opt.GPU:
        device = torch.device("cuda")
        noise = noise.to(device)
        inputs = inputs.to(device)
        labels = labels.to(device)
        fixed_noise = fixed_noise.to(device)

    #####################################
    # Train discriminator with real_img #
    #####################################
    optimD.zero_grad()
    outputs_real = discriminator(inputs)
    loss_d_real = criterion(outputs_real.squeeze(), labels)
    loss_d_real.backward()
    optimD.step()

    # print('Discriminator is trained with real image')
    ##########################################
    # Train discriminator with generated_img #
    ##########################################
    generated_img = generator(noise).detach()
    outputs_fake = discriminator(generated_img)
    loss_d_fake = criterion(outputs_fake.squeeze(), labels.fill_(0))
    loss_d_fake.backward()
    optimD.step()

    total_d_loss = loss_d_real + loss_d_fake
    ######################################
    # Train generator with generated_img #
    ######################################
    generator.zero_grad()
    generated_img = generator(noise.normal_(0,1))
    outputs_g = discriminator(generated_img)
    loss_g = criterion(outputs_g.squeeze(), labels.fill_(1)) # Mark generated images as positive
    total_g_loss = loss_g.clone()
    loss_g.backward()
    optimG.step()
    
    
    if ix != 0 and (ix % (round(num_batch/4)) == 0 or ix == num_batch):
        loss_d_list.append(total_d_loss)
        loss_g_list.append(total_g_loss)
        print('Finish batch {}/{} at epoch {}'.format(ix,num_batch, i))
    
  plt.figure(figsize=(12, 12))
  for j in range(opt.num_observation):
    plt.subplot(4, 4, j+1)

    plt.axis('off')
  plt.suptitle('Generated images after epoch {}'.format(i), fontsize = 24)
  plt.show()
  
  if i+1 % 10 == 0: # Save models for every 10 epochs
      torch.save(generator, r'G:\My Drive\Colab Notebooks\PyTorch DCGAN\netG_epoch{}'.format(i))
      torch.save(discriminator, r'G:\My Drive\Colab Notebooks\PyTorch DCGAN\netD_epoch{}'.format(i))
      
plt.plot(range(len(loss_d_list)), [tensors.to('cpu').detach().numpy() for tensors in loss_d_list],
         color = 'red', label = 'Discriminator Loss')
plt.plot(range(len(loss_g_list)), [tensors.to('cpu').detach().numpy() for tensors in loss_g_list],
         label = 'Generator Loss')

plt.legend()
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.title('Loss History')
plt.show()



